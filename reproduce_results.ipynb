{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508daf35-8def-45a5-b16f-94adfe0ac821",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4f2b18-c81b-48d2-933d-254e3518bf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e713bafc-2a7d-4021-8d61-29ad9b368238",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn import Classifier, train_classifier\n",
    "from confidence_eval import get_confidence_inference, get_percentiles_inference, get_confidence_mcdropout, get_confidence_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8272719d-89c5-4180-81eb-107e5d1246f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d3f763-aef9-4e28-9a39-318d29c9b0b7",
   "metadata": {},
   "source": [
    "First of all, we download the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016a5849-4e00-474b-8278-2af735b82af3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainset_all = torchvision.datasets.MNIST('./datasets', train=True, download=True, transform=torchvision.transforms.ToTensor())\n",
    "testset_all = torchvision.datasets.MNIST('./datasets', train=False, download=True, transform=torchvision.transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae01fa2-55b9-4b41-9e59-2ac2c086c144",
   "metadata": {},
   "source": [
    "The dataset is placed here in a dictionary where keys are all the unique values of the labels, and each key in the dictionary returns all the instances of the dataset relative to that key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6d2c1e-2998-4142-baff-f84dd1ea2f92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset_all, batch_size=1)\n",
    "testloader = torch.utils.data.DataLoader(testset_all, batch_size=1)\n",
    "\n",
    "x_dict_train = {}\n",
    "x_dict_test = {}\n",
    "\n",
    "count = 0\n",
    "for x,y in trainloader:\n",
    "    if count==int(len(trainloader)):\n",
    "        break\n",
    "    count = count + 1\n",
    "    if str(y.numpy()[0]) in x_dict_train.keys():\n",
    "        x_dict_train[str(y.numpy()[0])] = torch.cat([x_dict_train[str(y.numpy()[0])], x])\n",
    "    else:\n",
    "        x_dict_train[str(y.numpy()[0])] = x\n",
    "        \n",
    "count = 0        \n",
    "for x,y in testloader:\n",
    "    if count==int(len(testloader)):\n",
    "        break\n",
    "    count = count + 1\n",
    "    \n",
    "    if str(y.numpy()[0]) in x_dict_test.keys():\n",
    "        x_dict_test[str(y.numpy()[0])] = torch.cat([x_dict_test[str(y.numpy()[0])], x])\n",
    "    else:\n",
    "        x_dict_test[str(y.numpy()[0])] = x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdcfe2f-fd4d-4977-8bca-80f0fd7405ac",
   "metadata": {},
   "source": [
    "We select an out-of-distribution value (ood) and build datasets (train and test) that do not contain the ood value, and a dataset that contains only ood values as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005b41ea-3c7b-481f-b005-84e3cadb5807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_datasets ( ood, x_dict_train, x_dict_test):\n",
    "    trainset_x = torch.tensor([])\n",
    "    trainset_y = torch.tensor([])\n",
    "    testset_x = torch.tensor([])\n",
    "    testset_y = torch.tensor([])\n",
    "    oodset = torch.tensor([])\n",
    "\n",
    "    for key in x_dict_train.keys():\n",
    "        if key != str(ood):\n",
    "            trainset_x = torch.cat([trainset_x, x_dict_train[key]])\n",
    "            trainset_y = torch.cat([trainset_y, float(key)*torch.ones([len(x_dict_train[key])])])\n",
    "        else:\n",
    "            oodset_x = torch.cat([oodset, x_dict_train[key]])\n",
    "\n",
    "    for key in x_dict_train.keys():\n",
    "        if key != str(ood):\n",
    "            testset_x = torch.cat([testset_x, x_dict_test[key]])\n",
    "            testset_y = torch.cat([testset_y, float(key)*torch.ones([len(x_dict_test[key])])])\n",
    "        else:\n",
    "            oodset_x = torch.cat([oodset, x_dict_test[key]])\n",
    "\n",
    "    trainset = torch.utils.data.TensorDataset(trainset_x, trainset_y.long())\n",
    "    testset = torch.utils.data.TensorDataset(testset_x, testset_y.long())\n",
    "    oodset = torch.utils.data.TensorDataset(oodset_x, ood*torch.ones([len(oodset_x)]))\n",
    "\n",
    "    return trainset, testset, oodset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9073e5ec-07af-4a7c-9dd6-b94155c68023",
   "metadata": {},
   "outputs": [],
   "source": [
    "ood = 2\n",
    "trainset, testset, oodset = build_datasets(ood, x_dict_train, x_dict_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a209f2a-561c-47d3-ac90-8e9b02de9ca2",
   "metadata": {},
   "source": [
    "Here, we can visualize the composition of the sets built above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708491ae-261c-4956-96ba-df41ffafe10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow = 20\n",
    "fig, axs = plt.subplots(3,1, figsize=(10,5))\n",
    "\n",
    "loader = torch.utils.data.DataLoader(trainset, batch_size=nrow, shuffle=True)\n",
    "x,y = next(iter(loader))\n",
    "x_im = torchvision.utils.make_grid(x, nrow=nrow)\n",
    "axs[0].imshow(np.transpose(x_im.numpy(), (1, 2, 0)))\n",
    "axs[0].set_title('train set')\n",
    "\n",
    "loader = torch.utils.data.DataLoader(testset, batch_size=nrow, shuffle=True)\n",
    "x,y = next(iter(loader))\n",
    "x_im = torchvision.utils.make_grid(x, nrow=nrow)\n",
    "axs[1].imshow(np.transpose(x_im.numpy(), (1, 2, 0)))\n",
    "axs[1].set_title('test set')\n",
    "\n",
    "loader = torch.utils.data.DataLoader(oodset, batch_size=nrow, shuffle=True)\n",
    "x,y = next(iter(loader))\n",
    "x_im = torchvision.utils.make_grid(x, nrow=nrow)\n",
    "axs[2].imshow(np.transpose(x_im.numpy(), (1, 2, 0)))\n",
    "axs[2].set_title('ood set')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7923056a-9273-4df5-b5e3-928483220ff7",
   "metadata": {},
   "source": [
    "Let's train a nn classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01598e50-d06a-453e-8f67-4afa92343be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ood = 0\n",
    "\n",
    "layers_nodes = [1024,1024]\n",
    "accuracy_target = 0.96\n",
    "\n",
    "q = (0.1,50)\n",
    "n_models_mcdropout = 10\n",
    "n_models_ensemble = 3\n",
    "\n",
    "trainset, testset, oodset = build_datasets(ood, x_dict_train, x_dict_test)\n",
    "\n",
    "classifiers = []\n",
    "\n",
    "for n in range (n_models_ensemble):\n",
    "    \n",
    "    classifier = Classifier(layers_nodes=layers_nodes, p=0.4).to(device)\n",
    "    trained = train_classifier(device, classifier, trainset, accuracy_target=accuracy_target, verbose = True)\n",
    "    while (trained == False):\n",
    "        classifier = Classifier(layers_nodes=layers_nodes, p=0.4).to(device)\n",
    "        trained = train_classifier(device, classifier, trainset, accuracy_target=accuracy_target, verbose = True)\n",
    "    classifiers.append(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44df3823-41c0-4fa8-9741-02bb61bed94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_test = torch.utils.data.DataLoader(testset, batch_size=len(testset))\n",
    "x_test,y_test = next(iter(loader_test))\n",
    "y_test = y_test.numpy()\n",
    "loader_ood = torch.utils.data.DataLoader(oodset, batch_size=len(oodset))\n",
    "x_ood,_ = next(iter(loader_ood))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b56dc60-9162-4d8e-9b8d-7f4e99d1cbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = classifiers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc28422-beef-41d1-ad0d-d5f639212de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles, mean, cov, scale_mean, scale_std = get_percentiles_inference(classifier, x_dict_train, ood, q)\n",
    "\n",
    "prediction_test_inference, confidence_test_inference = get_confidence_inference(x_test, classifier, percentiles, mean, cov, scale_mean, scale_std)  \n",
    "classified_inference = y_test==prediction_test_inference\n",
    "misclassified_inference = y_test!=prediction_test_inference\n",
    "prediction_ood_inference, confidence_ood_inference = get_confidence_inference(x_ood, classifier, percentiles, mean, cov, scale_mean, scale_std)         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d60425-d37c-45de-83ae-d24a3fe37bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "acceptance_inference = 0.5\n",
    "\n",
    "print('True positive classified: ', np.mean(confidence_test_inference[classified_inference]>acceptance_inference))\n",
    "print('True negative misclassified: ', np.mean(confidence_test_inference[misclassified_inference]<acceptance_inference))\n",
    "print('True negative ood: ', np.mean(confidence_ood_inference<acceptance_inference))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c430c868-027b-40d2-9dbf-403ff0490cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,3, figsize=(12,4))\n",
    "bins = np.linspace(0, 1, num=11)\n",
    "\n",
    "\n",
    "axs[0].hist(confidence_ood_inference, bins=bins, width=0.1, alpha=0.7, density=True)\n",
    "axs[0].set_xlabel('Confidence')\n",
    "axs[0].set_ylabel('Normalized Counts')\n",
    "axs[0].set_title('Out-of-distribution')\n",
    "axs[0].set_xticks(bins)\n",
    "axs[0].grid(True)\n",
    "axs[0].legend(['Inference'])\n",
    "\n",
    "axs[1].hist(confidence_test_inference[misclassified_inference], bins=bins, width=0.1, alpha=0.7, density=True)\n",
    "axs[1].set_xlabel('Confidence')\n",
    "axs[1].set_title('Misclassified')\n",
    "axs[1].set_xticks(bins)\n",
    "axs[1].grid(True)\n",
    "axs[1].legend(['Inference'])\n",
    "\n",
    "axs[2].hist(confidence_test_inference[classified_inference], bins=bins, width=0.1, alpha=0.7, density=True)\n",
    "axs[2].set_xlabel('Confidence')\n",
    "axs[2].set_title('Classified')\n",
    "axs[2].set_xticks(bins)\n",
    "axs[2].grid(True)\n",
    "axs[2].legend(['Inference'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6274ce46-4e3b-43a6-9559-3b7f92278411",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test_mcdropout, confidence_test_mcdropout = get_confidence_mcdropout(x_test, classifiers[0], n_models_mcdropout)\n",
    "classified_mcdropout = y_test==prediction_test_mcdropout\n",
    "misclassified_mcdropout = y_test!=prediction_test_mcdropout\n",
    "prediction_ood_mcdropout, confidence_ood_mcdropout = get_confidence_mcdropout(x_ood, classifiers[0], n_models_mcdropout)\n",
    "\n",
    "print('True positive classified: ', np.mean(confidence_test_mcdropout[classified_mcdropout]>0.99))\n",
    "print('True negative misclassified: ', np.mean(confidence_test_mcdropout[misclassified_mcdropout]<0.99))\n",
    "print('True negative ood: ', np.mean(confidence_ood_mcdropout<0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10559d4-2f30-42d3-9268-31cba67a16a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,3, figsize=(12,4))\n",
    "bins = np.linspace(0, 1, num=11)\n",
    "\n",
    "axs[0].hist(confidence_ood_mcdropout, bins=bins, alpha=0.7, density=True)\n",
    "axs[0].set_xlabel('Confidence')\n",
    "axs[0].set_ylabel('Normalized Counts')\n",
    "axs[0].set_title('Out-of-distribution')\n",
    "axs[0].set_xticks(bins)\n",
    "axs[0].grid(True)\n",
    "axs[0].legend(['MC-dropout'])\n",
    "\n",
    "axs[1].hist(confidence_test_mcdropout[misclassified_mcdropout],bins=bins, width=0.1, alpha=0.7, density=True)\n",
    "axs[1].set_xlabel('Confidence')\n",
    "axs[1].set_title('Misclassified')\n",
    "axs[1].set_xticks(bins)\n",
    "axs[1].grid(True)\n",
    "axs[1].legend(['MC-dropout'])\n",
    "\n",
    "axs[2].hist(confidence_test_mcdropout[classified_mcdropout],bins=bins, width=0.1, alpha=0.7, density=True)\n",
    "axs[2].set_xlabel('Confidence')\n",
    "axs[2].set_title('Classified')\n",
    "axs[2].set_xticks(bins)\n",
    "axs[2].grid(True)\n",
    "axs[2].legend(['MC-dropout'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8277aea-476c-4623-b522-982359a1162f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction_test_ensemble, confidence_test_ensemble = get_confidence_ensemble(x_test, classifiers)\n",
    "classified_ensemble = y_test==prediction_test_ensemble\n",
    "misclassified_ensemble = y_test!=prediction_test_ensemble\n",
    "prediction_ood_ensemble, confidence_ood_ensemble = get_confidence_ensemble(x_ood, classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374c0cd7-02b3-478c-b5b4-e1b4c994f647",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('True positive classified: ', np.mean(confidence_test_ensemble[classified_ensemble]>0.99))\n",
    "print('True negative misclassified: ', np.mean(confidence_test_ensemble[misclassified_ensemble]<0.99))\n",
    "print('True negative ood: ', np.mean(confidence_ood_ensemble<0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3d551a-3d5d-42b0-b1b0-7ff7628a0f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,3, figsize=(12,4))\n",
    "bins = np.linspace(0, 1, num=11)\n",
    "\n",
    "axs[0].hist(confidence_ood_ensemble, bins=bins, alpha=0.7, density=True)\n",
    "axs[0].set_xlabel('Confidence')\n",
    "axs[0].set_ylabel('Normalized Counts')\n",
    "axs[0].set_title('Out-of-distribution')\n",
    "axs[0].set_xticks(bins)\n",
    "axs[0].grid(True)\n",
    "axs[0].legend(['Ensemble'])\n",
    "\n",
    "axs[1].hist(confidence_test_ensemble[misclassified_ensemble],bins=bins, width=0.1, alpha=0.7, density=True)\n",
    "axs[1].set_xlabel('Confidence')\n",
    "axs[1].set_title('Misclassified')\n",
    "axs[1].set_xticks(bins)\n",
    "axs[1].grid(True)\n",
    "axs[1].legend(['Ensemble'])\n",
    "\n",
    "axs[2].hist(confidence_test_ensemble[classified_ensemble],bins=bins, width=0.1, alpha=0.7, density=True)\n",
    "axs[2].set_xlabel('Confidence')\n",
    "axs[2].set_title('Classified')\n",
    "axs[2].set_xticks(bins)\n",
    "axs[2].grid(True)\n",
    "axs[2].legend(['Ensemble'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eae6deb-5f3a-4a16-b1d9-b57b52994885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_experiment(layers_nodes, accuracy_target, epochs, batch_size, step_scheduler, p,\n",
    "                   n_models_mcdropout, n_models_ensemble, acceptance_inference, acceptance_mcdropout, acceptance_ensemble) :\n",
    "\n",
    "    tp_classified_inference = {}\n",
    "    tn_misclassified_inference = {}\n",
    "    tn_ood_inference = {}\n",
    "    for q in q_values:    \n",
    "        tp_classified_inference[q] = []\n",
    "        tn_misclassified_inference[q] = []\n",
    "        tn_ood_inference[q] = []\n",
    "\n",
    "    tp_classified_mcdropout = []\n",
    "    tn_misclassified_mcdropout = []\n",
    "    tn_ood_mcdropout = []\n",
    "\n",
    "    tp_classified_ensemble = []\n",
    "    tn_misclassified_ensemble = []\n",
    "    tn_ood_ensemble = []\n",
    "        \n",
    "        \n",
    "    for ood in range (10):\n",
    "\n",
    "        print(ood)\n",
    "\n",
    "        trainset, testset, oodset = build_datasets(ood, x_dict_train, x_dict_test)\n",
    "        classifiers = []\n",
    "\n",
    "        for n in range (n_models_ensemble):\n",
    "\n",
    "            classifier = Classifier(layers_nodes=layers_nodes, p=p).to(device)\n",
    "            trained = train_classifier(device, classifier, trainset, accuracy_target=accuracy_target, epochs=epochs, batch_size=batch_size, step_scheduler=step_scheduler, verbose = True)\n",
    "            while (trained == False):\n",
    "                classifier = Classifier(layers_nodes=layers_nodes, p=p).to(device)\n",
    "                trained = train_classifier(device, classifier, trainset, accuracy_target=accuracy_target, epochs=epochs, batch_size=batch_size, step_scheduler=step_scheduler,  verbose = True)\n",
    "            classifiers.append(classifier)\n",
    "\n",
    "            \n",
    "        loader = torch.utils.data.DataLoader(testset, batch_size=len(testset))\n",
    "        x_test,y_test = next(iter(loader))\n",
    "        y_test = y_test.cpu().numpy()\n",
    "        loader = torch.utils.data.DataLoader(oodset, batch_size=len(oodset))\n",
    "        x_ood,_ = next(iter(loader))\n",
    "\n",
    "        for q in q_values:\n",
    "            percentiles, mean, cov, scale_mean, scale_std = get_percentiles_inference(classifiers[0], x_dict_train, ood, q)\n",
    "            prediction_test_inference, confidence_test_inference = get_confidence_inference(x_test, classifiers[0], percentiles, mean, cov, scale_mean, scale_std)         \n",
    "            classified_inference = y_test==prediction_test_inference\n",
    "            misclassified_inference = y_test!=prediction_test_inference\n",
    "            prediction_ood_inference, confidence_ood_inference = get_confidence_inference(x_ood, classifiers[0], percentiles, mean, cov, scale_mean, scale_std)         \n",
    "\n",
    "            tp_classified_inference[q].append(np.mean(confidence_test_inference[classified_inference]>acceptance_inference))\n",
    "            tn_misclassified_inference[q].append(np.mean(confidence_test_inference[misclassified_inference]<acceptance_inference))\n",
    "            tn_ood_inference[q].append(np.mean(confidence_ood_inference<acceptance_inference))\n",
    "\n",
    "\n",
    "        prediction_test_mcdropout, confidence_test_mcdropout = get_confidence_mcdropout(x_test, classifiers[0], n_models_mcdropout)\n",
    "        classified_mcdropout = y_test==prediction_test_mcdropout\n",
    "        misclassified_mcdropout = y_test!=prediction_test_mcdropout\n",
    "        prediction_ood_mcdropout, confidence_ood_mcdropout = get_confidence_mcdropout(x_ood, classifiers[0], n_models_mcdropout)\n",
    "\n",
    "        tp_classified_mcdropout.append(np.mean(confidence_test_mcdropout[classified_mcdropout]>acceptance_mcdropout))\n",
    "        tn_misclassified_mcdropout.append(np.mean(confidence_test_mcdropout[misclassified_mcdropout]<acceptance_mcdropout))\n",
    "        tn_ood_mcdropout.append(np.mean(confidence_ood_mcdropout<acceptance_mcdropout))\n",
    "\n",
    "\n",
    "        prediction_test_ensemble, confidence_test_ensemble = get_confidence_ensemble(x_test, classifiers)\n",
    "        classified_ensemble = y_test==prediction_test_ensemble\n",
    "        misclassified_ensemble = y_test!=prediction_test_ensemble\n",
    "        prediction_ood_ensemble, confidence_ood_ensemble = get_confidence_ensemble(x_ood, classifiers) \n",
    "\n",
    "        tp_classified_ensemble.append(np.mean(confidence_test_ensemble[classified_ensemble]>acceptance_ensemble))\n",
    "        tn_misclassified_ensemble.append(np.mean(confidence_test_ensemble[misclassified_ensemble]<acceptance_ensemble))\n",
    "        tn_ood_ensemble.append(np.mean(confidence_ood_ensemble<acceptance_ensemble))\n",
    "        \n",
    "    for q in q_values:\n",
    "        print('Inference method: ')\n",
    "        print('-q: ', q)\n",
    "        print('TP classified: ',np.around(np.mean(tp_classified_inference[q]),3), np.around(np.std(tp_classified_inference[q]),3))\n",
    "        print('TN misclassified: ', np.around(np.mean(tn_misclassified_inference[q]),3), np.around(np.std(tn_misclassified_inference[q]),3))\n",
    "        print('TN ood: ', np.around(np.mean(tn_ood_inference[q]),3), np.around(np.std(tn_ood_inference[q]),3))\n",
    "\n",
    "    print('')              \n",
    "    print('MC-dropout method: ')\n",
    "    print('TP classified: ', np.around(np.mean(tp_classified_mcdropout),3), np.around(np.std(tp_classified_mcdropout),3))\n",
    "    print('TN misclassified: ', np.around(np.mean(tn_misclassified_mcdropout),3), np.around(np.std(tn_misclassified_mcdropout),3))\n",
    "    print('TN ood: ', np.around(np.mean(tn_ood_mcdropout),3), np.around(np.std(tn_ood_mcdropout),3))\n",
    "    \n",
    "    print('')\n",
    "    print('Ensemble method: ')\n",
    "    print('TP classified: ', np.around(np.mean(tp_classified_ensemble),3), np.around(np.std(tp_classified_ensemble),3))\n",
    "    print('TN misclassified: ', np.around(np.mean(tn_misclassified_ensemble),3), np.around(np.std(tn_misclassified_ensemble),3))\n",
    "    print('TN ood: ', np.around(np.mean(tn_ood_ensemble),3), np.around(np.std(tn_ood_ensemble),3))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8778cc-b7b0-4271-bebd-c7428b5a6f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_target = 0.965\n",
    "epochs = 16\n",
    "batch_size = 16\n",
    "step_scheduler = 3\n",
    "\n",
    "n_models_mcdropout = 100\n",
    "n_models_ensemble = 1\n",
    "\n",
    "acceptance_inference = 0.5\n",
    "acceptance_mcdropout = 0.99\n",
    "acceptance_ensemble = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caeb54fc-6c0f-4b82-b1a9-a9f3d7b0bc04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q_values = [(0.01,1),(0.1,50),(3,90)]\n",
    "layers_nodes = [1024,1024]\n",
    "p=0.5\n",
    "\n",
    "\n",
    "perform_experiment(layers_nodes=layers_nodes, accuracy_target=accuracy_target, epochs=epochs, batch_size=batch_size, step_scheduler=step_scheduler, p=p,\n",
    "                   n_models_mcdropout=n_models_mcdropout, n_models_ensemble=n_models_ensemble, \n",
    "                   acceptance_inference=acceptance_inference, acceptance_mcdropout=acceptance_mcdropout, acceptance_ensemble=acceptance_ensemble) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e7e7cd-f1b9-469e-9bc3-eb691657c6bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q_values = [(0.01,1),(0.1,50),(3,90)]\n",
    "layers_nodes = [1024,1024]\n",
    "p=0.2\n",
    "\n",
    "\n",
    "perform_experiment(layers_nodes=layers_nodes, accuracy_target=accuracy_target, epochs=epochs, batch_size=batch_size, step_scheduler=step_scheduler, p=p,\n",
    "                   n_models_mcdropout=n_models_mcdropout, n_models_ensemble=n_models_ensemble, \n",
    "                   acceptance_inference=acceptance_inference, acceptance_mcdropout=acceptance_mcdropout, acceptance_ensemble=acceptance_ensemble) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105f1824-403b-4820-b844-49332e29869f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q_values = [(2,10),(3,50),(7,90)]\n",
    "layers_nodes = [256,256,256,256]\n",
    "p=0.1\n",
    "\n",
    "\n",
    "perform_experiment(layers_nodes=layers_nodes, accuracy_target=accuracy_target, epochs=epochs, batch_size=batch_size, step_scheduler=step_scheduler, p=p,\n",
    "                   n_models_mcdropout=n_models_mcdropout, n_models_ensemble=n_models_ensemble, \n",
    "                   acceptance_inference=acceptance_inference, acceptance_mcdropout=acceptance_mcdropout, acceptance_ensemble=acceptance_ensemble) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e4a328-9793-492d-996d-2c272a838549",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q_values = [(2,10),(3,50),(7,90)]\n",
    "layers_nodes = [256,256,256,256]\n",
    "p=0.25\n",
    "\n",
    "\n",
    "perform_experiment(layers_nodes=layers_nodes, accuracy_target=accuracy_target, epochs=epochs, batch_size=batch_size, step_scheduler=step_scheduler, p=p,\n",
    "                   n_models_mcdropout=n_models_mcdropout, n_models_ensemble=n_models_ensemble, \n",
    "                   acceptance_inference=acceptance_inference, acceptance_mcdropout=acceptance_mcdropout, acceptance_ensemble=acceptance_ensemble) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c1f2ab-949e-412c-82d8-1d8ac91882e1",
   "metadata": {},
   "source": [
    "Let's quantify uncertainty."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
